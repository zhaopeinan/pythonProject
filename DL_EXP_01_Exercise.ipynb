{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 一、Pytorch基本操作考察（平台课+专业课）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1.\n",
    "# 使用 𝐓𝐞𝐧𝐬𝐨𝐫 初始化一个 𝟏 × 𝟑 的矩阵 𝑴 和一个 𝟐 × 𝟏 的矩阵 𝑵，对两矩阵进行减法操作（要求实现三种不同的形式），给出结果并分析三种方式的不同（如果出现报错，分析报错的原因），同时需要指出在计算过程中发生了什么"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3, -4],\n",
      "        [-2, -3],\n",
      "        [-1, -2]])\n"
     ]
    }
   ],
   "source": [
    "M = torch.tensor([[1], [2], [3]])\n",
    "N = torch.tensor([4, 5])\n",
    "Q = M - N\n",
    "print(Q)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3, -4],\n",
      "        [-2, -3],\n",
      "        [-1, -2]])\n"
     ]
    }
   ],
   "source": [
    "M_2 = torch.rand_like(M, dtype=torch.float)\n",
    "N_2 = torch.rand_like(N, dtype=torch.float)\n",
    "Q_2 = M - N\n",
    "print(Q_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "M_3 = torch.ones(1, 3)\n",
    "N_3 = torch.ones(2, 1)\n",
    "Q_3 = M_3 - N_3\n",
    "print(Q_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "减法1 = tensor([[-3, -4],\n",
      "        [-2, -3],\n",
      "        [-1, -2]])\n",
      "剑法2 = tensor([[-3, -4],\n",
      "        [-2, -3],\n",
      "        [-1, -2]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [3, 1] doesn't match the broadcast shape [3, 2]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m减法1 = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(M \u001B[38;5;241m-\u001B[39m N))\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m剑法2 = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(M\u001B[38;5;241m.\u001B[39msubtract(N)))\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m剑法3 = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[43mM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m)\u001B[49m))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: output with shape [3, 1] doesn't match the broadcast shape [3, 2]"
     ]
    }
   ],
   "source": [
    "print(\"减法1 = {}\".format(M - N))\n",
    "print(\"剑法2 = {}\".format(M.subtract(N)))\n",
    "print(\"剑法3 = {}\".format(M.sub_(N)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 前两种减法会形成广播，两个矩阵均变为3 x 2形状，第三种不形成广播所以提示形状报错"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2.\n",
    "# ① 利用 𝐓𝐞𝐧𝐬𝐨𝐫 创建两个大小分别 𝟑 × 𝟐 和 𝟒 × 𝟐 的随机数矩阵 𝑷 和 𝑸 ，要求服从均值为0，标准差0.01为的正态分布"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0015, -0.0076],\n",
      "        [ 0.0172,  0.0250],\n",
      "        [ 0.0125, -0.0004]])\n",
      "tensor([[ 0.0008,  0.0104],\n",
      "        [-0.0054, -0.0046],\n",
      "        [-0.0199,  0.0153],\n",
      "        [-0.0008, -0.0010]])\n"
     ]
    }
   ],
   "source": [
    "P = torch.normal(0, 0.01, (3, 2))\n",
    "Q = torch.normal(0, 0.01, (4, 2))\n",
    "print(P)\n",
    "print(Q)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ② 对第二步得到的矩阵 𝑸 进行形状变换得到 𝑸 的转置 𝑸𝑻"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0008, -0.0054, -0.0199, -0.0008],\n",
      "        [ 0.0104, -0.0046,  0.0153, -0.0010]])\n"
     ]
    }
   ],
   "source": [
    "QT = Q.T\n",
    "print(QT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ③ 对上述得到的矩阵 𝑷 和矩阵 𝑸𝑻 求矩阵相乘"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.8270e-05,  2.7024e-05, -1.4622e-04,  6.4623e-06],\n",
      "        [ 2.7337e-04, -2.0765e-04,  4.1129e-05, -3.8444e-05],\n",
      "        [ 5.4841e-06, -6.5841e-05, -2.5488e-04, -9.4149e-06]])\n"
     ]
    }
   ],
   "source": [
    "PQT = torch.mm(P, QT)\n",
    "print(PQT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3.\n",
    "# 给定公式 𝑦3 = 𝑦1 + 𝑦2 = 𝑥^2 + 𝑥^3，且 𝑥 = 1。利用学习所得到的Tensor的相关知识，求𝑦3对𝑥的梯度，即𝑑𝑦3/𝑑𝑥\n",
    "# 要求在计算过程中，在计算 𝑥^3 时中断梯度的追踪，观察结果并进行原因分析\n",
    "# 提示, 可使用 with torch.no_grad()， 举例:\n",
    "# with torch.no_grad():\n",
    "# y = x * 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0], dtype=float, requires_grad=True)\n",
    "y1 = x * x\n",
    "with torch.no_grad():\n",
    "    y2 = x * x * x\n",
    "y3 = y1 + y2\n",
    "y3.backward()\n",
    "print(x.grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# 二、动手实现 logistic 回归（平台课+专业课）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# 1. 要求动手从0实现 logistic 回归（只借助Tensor和Numpy相关的库）在人工构造的数据集上进行训练和测试，并从loss以及训练集上的准确率等多个角度对结果进行分析\n",
    "# （可借助nn.BCELoss或nn.BCEWithLogitsLoss作为损失函数，从零实现二元交叉熵为选作）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义生成数据集的绘图函数\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "def set_figsize(ipython_format, figsize=(3.5, 2.5)):\n",
    "    matplotlib_inline.backend_inline.set_matplotlib_formats(ipython_format)\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "# set_figsize('svg')\n",
    "# plt.scatter(features[:, 1].numpy(), labels.numpy(), 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 定义损失与正确率的绘图函数\n",
    "def figplot(fignum, loss, acc):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.suptitle('Figure ' + str(fignum))\n",
    "    # 打印损失值\n",
    "    plt.subplot(121)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss[0],label='Train Loss')\n",
    "    plt.plot(loss[1],label='Test Loss')\n",
    "    plt.legend()\n",
    "    # 打印正确率\n",
    "    plt.subplot(122)\n",
    "    plt.ylabel('ACC')\n",
    "    plt.plot(acc[0],label='Train Acc')\n",
    "    plt.plot(acc[1],label='Test Acc')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# 人工构造数据集函数\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def generate_data(num_examples, num_inputs, true_w, true_b):\n",
    "    features = torch.tensor(np.random.rand(num_examples, num_inputs), dtype=torch.float)\n",
    "    labels = 1 / (1 + torch.exp(-1 * (true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b)))\n",
    "    labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)\n",
    "    result_0 = 0\n",
    "    result_1 = 0\n",
    "    for i in range(num_examples):\n",
    "        if labels[i] < 0.5:\n",
    "            labels[i] = 0\n",
    "            result_0 += 1\n",
    "        else:\n",
    "            labels[i] = 1\n",
    "            result_1 += 1\n",
    "    return features, labels, result_0, result_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集共有数据2000个，其中标签为'0'的数量为 1000， 标签为'1'的数量为 1000\n",
      "测试集共有数据1000个，其中标签为'0'的数量为 465， 标签为'1'的数量为 535\n"
     ]
    }
   ],
   "source": [
    "# 生成训练数据集与测试数据集并进行可视化展示\n",
    "num_inputs = 2\n",
    "true_w = [2, -3.4]\n",
    "true_b = 0.7\n",
    "train_examples,test_examples = 2000, 1000\n",
    "train_data,train_labels, train_0, train_1 = generate_data(train_examples,num_inputs, true_w, true_b)\n",
    "test_data, test_labels, test_0, test_1 = generate_data(test_examples,num_inputs, true_w, true_b)\n",
    "print(\"训练集共有数据%d个，其中标签为'0'的数量为 %d， 标签为'1'的数量为 %d\"%(train_examples,train_0,train_1))\n",
    "print(\"测试集共有数据%d个，其中标签为'0'的数量为 %d， 标签为'1'的数量为 %d\"%(test_examples,test_0,test_1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# 定义数据读取函数\n",
    "import random\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices) # 样本的读取顺序是随机的\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # 最后一次可能不足一个batch\n",
    "        yield features.index_select(0, j), labels.index_select(0, j)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# 构建logistic模型\n",
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32)\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)\n",
    "def logistic(X, w, b):\n",
    "    logistic_func = 1 / (1 + torch.exp(-1 * (torch.mm(X, w) + b)))\n",
    "    return logistic_func"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# 定义优化函数\n",
    "def sgd(params, lr, batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # 注意这里更改param时用的param.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "from torch.nn import BCELoss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "epoch: 1 loss:0.15019 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 10 loss:0.14990 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 20 loss:0.14959 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 30 loss:0.14928 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 40 loss:0.14896 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 50 loss:0.14866 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 60 loss:0.14835 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 70 loss:0.14805 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 80 loss:0.14775 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 90 loss:0.14745 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 100 loss:0.14715 \n"
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "lr = 0.6\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "net = logistic\n",
    "loss = BCELoss()\n",
    "train_all_loss = []\n",
    "acc_all = []\n",
    "for epoch in range(num_epochs): # 训练模型一共需要num_epochs个迭代周期\n",
    "    # 在每一个迭代周期中，会使用训练数据集中所有样本一次\n",
    "    for X, y in data_iter(batch_size, train_data, train_labels): # x和y分别是小批量样本的特征和标签\n",
    "        pred = net(X, w, b)\n",
    "        y = y.view(-1, 1)\n",
    "        train_each_loss = loss(pred, y)\n",
    "        train_each_loss.backward() # 反向传播\n",
    "        sgd([w,b], lr, batch_size) # 使用小批量随机梯度下降迭代模型参数\n",
    "        # 梯度清零\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    labels_pred = net(train_data, w, b)\n",
    "    train_loss = loss(labels_pred, train_labels.view(-1, 1))\n",
    "    train_all_loss.append(train_loss.item())\n",
    "    labels_pred = torch.tensor(np.where(labels_pred<0.5, 0, 1),dtype=torch.float32)\n",
    "    # acc = (labels_pred==train_labels).sum(0).item() / train_examples\n",
    "    acc = len((labels_pred==train_labels).sum(0))\n",
    "    # max_acc = max(acc,max_acc)\n",
    "    # acc_all.append(acc)\n",
    "    # if epoch==0 or (epoch+1) % 10 == 0:\n",
    "    #     print('epoch: %d loss:%.5f acc: %.3f'%(epoch+1, train_loss.item(), acc))\n",
    "    if epoch==0 or (epoch+1) % 10 == 0:\n",
    "        print('epoch: %d loss:%.5f '%(epoch+1, train_loss.item()))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
