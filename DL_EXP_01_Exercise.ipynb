{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ä¸€ã€PytorchåŸºæœ¬æ“ä½œè€ƒå¯Ÿï¼ˆå¹³å°è¯¾+ä¸“ä¸šè¯¾ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1.\n",
    "# ä½¿ç”¨ ğ“ğğ§ğ¬ğ¨ğ« åˆå§‹åŒ–ä¸€ä¸ª ğŸ Ã— ğŸ‘ çš„çŸ©é˜µ ğ‘´ å’Œä¸€ä¸ª ğŸ Ã— ğŸ çš„çŸ©é˜µ ğ‘µï¼Œå¯¹ä¸¤çŸ©é˜µè¿›è¡Œå‡æ³•æ“ä½œï¼ˆè¦æ±‚å®ç°ä¸‰ç§ä¸åŒçš„å½¢å¼ï¼‰ï¼Œç»™å‡ºç»“æœå¹¶åˆ†æä¸‰ç§æ–¹å¼çš„ä¸åŒï¼ˆå¦‚æœå‡ºç°æŠ¥é”™ï¼Œåˆ†ææŠ¥é”™çš„åŸå› ï¼‰ï¼ŒåŒæ—¶éœ€è¦æŒ‡å‡ºåœ¨è®¡ç®—è¿‡ç¨‹ä¸­å‘ç”Ÿäº†ä»€ä¹ˆ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3, -4],\n",
      "        [-2, -3],\n",
      "        [-1, -2]])\n"
     ]
    }
   ],
   "source": [
    "M = torch.tensor([[1], [2], [3]])\n",
    "N = torch.tensor([4, 5])\n",
    "Q = M - N\n",
    "print(Q)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3, -4],\n",
      "        [-2, -3],\n",
      "        [-1, -2]])\n"
     ]
    }
   ],
   "source": [
    "M_2 = torch.rand_like(M, dtype=torch.float)\n",
    "N_2 = torch.rand_like(N, dtype=torch.float)\n",
    "Q_2 = M - N\n",
    "print(Q_2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "M_3 = torch.ones(1, 3)\n",
    "N_3 = torch.ones(2, 1)\n",
    "Q_3 = M_3 - N_3\n",
    "print(Q_3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å‡æ³•1 = tensor([[-3, -4],\n",
      "        [-2, -3],\n",
      "        [-1, -2]])\n",
      "å‰‘æ³•2 = tensor([[-3, -4],\n",
      "        [-2, -3],\n",
      "        [-1, -2]])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [3, 1] doesn't match the broadcast shape [3, 2]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124må‡æ³•1 = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(M \u001B[38;5;241m-\u001B[39m N))\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124må‰‘æ³•2 = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(M\u001B[38;5;241m.\u001B[39msubtract(N)))\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124må‰‘æ³•3 = \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[43mM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msub_\u001B[49m\u001B[43m(\u001B[49m\u001B[43mN\u001B[49m\u001B[43m)\u001B[49m))\n",
      "\u001B[1;31mRuntimeError\u001B[0m: output with shape [3, 1] doesn't match the broadcast shape [3, 2]"
     ]
    }
   ],
   "source": [
    "print(\"å‡æ³•1 = {}\".format(M - N))\n",
    "print(\"å‰‘æ³•2 = {}\".format(M.subtract(N)))\n",
    "print(\"å‰‘æ³•3 = {}\".format(M.sub_(N)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# å‰ä¸¤ç§å‡æ³•ä¼šå½¢æˆå¹¿æ’­ï¼Œä¸¤ä¸ªçŸ©é˜µå‡å˜ä¸º3 x 2å½¢çŠ¶ï¼Œç¬¬ä¸‰ç§ä¸å½¢æˆå¹¿æ’­æ‰€ä»¥æç¤ºå½¢çŠ¶æŠ¥é”™"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 2.\n",
    "# â‘  åˆ©ç”¨ ğ“ğğ§ğ¬ğ¨ğ« åˆ›å»ºä¸¤ä¸ªå¤§å°åˆ†åˆ« ğŸ‘ Ã— ğŸ å’Œ ğŸ’ Ã— ğŸ çš„éšæœºæ•°çŸ©é˜µ ğ‘· å’Œ ğ‘¸ ï¼Œè¦æ±‚æœä»å‡å€¼ä¸º0ï¼Œæ ‡å‡†å·®0.01ä¸ºçš„æ­£æ€åˆ†å¸ƒ"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0015, -0.0076],\n",
      "        [ 0.0172,  0.0250],\n",
      "        [ 0.0125, -0.0004]])\n",
      "tensor([[ 0.0008,  0.0104],\n",
      "        [-0.0054, -0.0046],\n",
      "        [-0.0199,  0.0153],\n",
      "        [-0.0008, -0.0010]])\n"
     ]
    }
   ],
   "source": [
    "P = torch.normal(0, 0.01, (3, 2))\n",
    "Q = torch.normal(0, 0.01, (4, 2))\n",
    "print(P)\n",
    "print(Q)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# â‘¡ å¯¹ç¬¬äºŒæ­¥å¾—åˆ°çš„çŸ©é˜µ ğ‘¸ è¿›è¡Œå½¢çŠ¶å˜æ¢å¾—åˆ° ğ‘¸ çš„è½¬ç½® ğ‘¸ğ‘»"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0008, -0.0054, -0.0199, -0.0008],\n",
      "        [ 0.0104, -0.0046,  0.0153, -0.0010]])\n"
     ]
    }
   ],
   "source": [
    "QT = Q.T\n",
    "print(QT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# â‘¢ å¯¹ä¸Šè¿°å¾—åˆ°çš„çŸ©é˜µ ğ‘· å’ŒçŸ©é˜µ ğ‘¸ğ‘» æ±‚çŸ©é˜µç›¸ä¹˜"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-7.8270e-05,  2.7024e-05, -1.4622e-04,  6.4623e-06],\n",
      "        [ 2.7337e-04, -2.0765e-04,  4.1129e-05, -3.8444e-05],\n",
      "        [ 5.4841e-06, -6.5841e-05, -2.5488e-04, -9.4149e-06]])\n"
     ]
    }
   ],
   "source": [
    "PQT = torch.mm(P, QT)\n",
    "print(PQT)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 3.\n",
    "# ç»™å®šå…¬å¼ ğ‘¦3 = ğ‘¦1 + ğ‘¦2 = ğ‘¥^2 + ğ‘¥^3ï¼Œä¸” ğ‘¥ = 1ã€‚åˆ©ç”¨å­¦ä¹ æ‰€å¾—åˆ°çš„Tensorçš„ç›¸å…³çŸ¥è¯†ï¼Œæ±‚ğ‘¦3å¯¹ğ‘¥çš„æ¢¯åº¦ï¼Œå³ğ‘‘ğ‘¦3/ğ‘‘ğ‘¥\n",
    "# è¦æ±‚åœ¨è®¡ç®—è¿‡ç¨‹ä¸­ï¼Œåœ¨è®¡ç®— ğ‘¥^3 æ—¶ä¸­æ–­æ¢¯åº¦çš„è¿½è¸ªï¼Œè§‚å¯Ÿç»“æœå¹¶è¿›è¡ŒåŸå› åˆ†æ\n",
    "# æç¤º, å¯ä½¿ç”¨ with torch.no_grad()ï¼Œ ä¸¾ä¾‹:\n",
    "# with torch.no_grad():\n",
    "# y = x * 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1.0], dtype=float, requires_grad=True)\n",
    "y1 = x * x\n",
    "with torch.no_grad():\n",
    "    y2 = x * x * x\n",
    "y3 = y1 + y2\n",
    "y3.backward()\n",
    "print(x.grad)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# äºŒã€åŠ¨æ‰‹å®ç° logistic å›å½’ï¼ˆå¹³å°è¯¾+ä¸“ä¸šè¯¾ï¼‰"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# 1. è¦æ±‚åŠ¨æ‰‹ä»0å®ç° logistic å›å½’ï¼ˆåªå€ŸåŠ©Tensorå’ŒNumpyç›¸å…³çš„åº“ï¼‰åœ¨äººå·¥æ„é€ çš„æ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•ï¼Œå¹¶ä»lossä»¥åŠè®­ç»ƒé›†ä¸Šçš„å‡†ç¡®ç‡ç­‰å¤šä¸ªè§’åº¦å¯¹ç»“æœè¿›è¡Œåˆ†æ\n",
    "# ï¼ˆå¯å€ŸåŠ©nn.BCELossæˆ–nn.BCEWithLogitsLossä½œä¸ºæŸå¤±å‡½æ•°ï¼Œä»é›¶å®ç°äºŒå…ƒäº¤å‰ç†µä¸ºé€‰ä½œï¼‰"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# å®šä¹‰ç”Ÿæˆæ•°æ®é›†çš„ç»˜å›¾å‡½æ•°\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "def set_figsize(ipython_format, figsize=(3.5, 2.5)):\n",
    "    matplotlib_inline.backend_inline.set_matplotlib_formats(ipython_format)\n",
    "    plt.rcParams['figure.figsize'] = figsize\n",
    "\n",
    "# set_figsize('svg')\n",
    "# plt.scatter(features[:, 1].numpy(), labels.numpy(), 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# å®šä¹‰æŸå¤±ä¸æ­£ç¡®ç‡çš„ç»˜å›¾å‡½æ•°\n",
    "def figplot(fignum, loss, acc):\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.suptitle('Figure ' + str(fignum))\n",
    "    # æ‰“å°æŸå¤±å€¼\n",
    "    plt.subplot(121)\n",
    "    plt.ylabel('Loss')\n",
    "    plt.plot(loss[0],label='Train Loss')\n",
    "    plt.plot(loss[1],label='Test Loss')\n",
    "    plt.legend()\n",
    "    # æ‰“å°æ­£ç¡®ç‡\n",
    "    plt.subplot(122)\n",
    "    plt.ylabel('ACC')\n",
    "    plt.plot(acc[0],label='Train Acc')\n",
    "    plt.plot(acc[1],label='Test Acc')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [],
   "source": [
    "# äººå·¥æ„é€ æ•°æ®é›†å‡½æ•°\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def generate_data(num_examples, num_inputs, true_w, true_b):\n",
    "    features = torch.tensor(np.random.rand(num_examples, num_inputs), dtype=torch.float)\n",
    "    labels = 1 / (1 + torch.exp(-1 * (true_w[0] * features[:, 0] + true_w[1] * features[:, 1] + true_b)))\n",
    "    labels += torch.tensor(np.random.normal(0, 0.01, size=labels.size()), dtype=torch.float)\n",
    "    result_0 = 0\n",
    "    result_1 = 0\n",
    "    for i in range(num_examples):\n",
    "        if labels[i] < 0.5:\n",
    "            labels[i] = 0\n",
    "            result_0 += 1\n",
    "        else:\n",
    "            labels[i] = 1\n",
    "            result_1 += 1\n",
    "    return features, labels, result_0, result_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è®­ç»ƒé›†å…±æœ‰æ•°æ®2000ä¸ªï¼Œå…¶ä¸­æ ‡ç­¾ä¸º'0'çš„æ•°é‡ä¸º 1000ï¼Œ æ ‡ç­¾ä¸º'1'çš„æ•°é‡ä¸º 1000\n",
      "æµ‹è¯•é›†å…±æœ‰æ•°æ®1000ä¸ªï¼Œå…¶ä¸­æ ‡ç­¾ä¸º'0'çš„æ•°é‡ä¸º 465ï¼Œ æ ‡ç­¾ä¸º'1'çš„æ•°é‡ä¸º 535\n"
     ]
    }
   ],
   "source": [
    "# ç”Ÿæˆè®­ç»ƒæ•°æ®é›†ä¸æµ‹è¯•æ•°æ®é›†å¹¶è¿›è¡Œå¯è§†åŒ–å±•ç¤º\n",
    "num_inputs = 2\n",
    "true_w = [2, -3.4]\n",
    "true_b = 0.7\n",
    "train_examples,test_examples = 2000, 1000\n",
    "train_data,train_labels, train_0, train_1 = generate_data(train_examples,num_inputs, true_w, true_b)\n",
    "test_data, test_labels, test_0, test_1 = generate_data(test_examples,num_inputs, true_w, true_b)\n",
    "print(\"è®­ç»ƒé›†å…±æœ‰æ•°æ®%dä¸ªï¼Œå…¶ä¸­æ ‡ç­¾ä¸º'0'çš„æ•°é‡ä¸º %dï¼Œ æ ‡ç­¾ä¸º'1'çš„æ•°é‡ä¸º %d\"%(train_examples,train_0,train_1))\n",
    "print(\"æµ‹è¯•é›†å…±æœ‰æ•°æ®%dä¸ªï¼Œå…¶ä¸­æ ‡ç­¾ä¸º'0'çš„æ•°é‡ä¸º %dï¼Œ æ ‡ç­¾ä¸º'1'çš„æ•°é‡ä¸º %d\"%(test_examples,test_0,test_1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "# å®šä¹‰æ•°æ®è¯»å–å‡½æ•°\n",
    "import random\n",
    "def data_iter(batch_size, features, labels):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices) # æ ·æœ¬çš„è¯»å–é¡ºåºæ˜¯éšæœºçš„\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        j = torch.LongTensor(indices[i: min(i + batch_size, num_examples)]) # æœ€åä¸€æ¬¡å¯èƒ½ä¸è¶³ä¸€ä¸ªbatch\n",
    "        yield features.index_select(0, j), labels.index_select(0, j)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [],
   "source": [
    "# æ„å»ºlogisticæ¨¡å‹\n",
    "w = torch.tensor(np.random.normal(0, 0.01, (num_inputs, 1)), dtype=torch.float32)\n",
    "b = torch.zeros(1, dtype=torch.float32)\n",
    "w.requires_grad_(requires_grad=True)\n",
    "b.requires_grad_(requires_grad=True)\n",
    "def logistic(X, w, b):\n",
    "    logistic_func = 1 / (1 + torch.exp(-1 * (torch.mm(X, w) + b)))\n",
    "    return logistic_func"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¼˜åŒ–å‡½æ•°\n",
    "def sgd(params, lr, batch_size):\n",
    "    for param in params:\n",
    "        param.data -= lr * param.grad / batch_size # æ³¨æ„è¿™é‡Œæ›´æ”¹paramæ—¶ç”¨çš„param.data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "# å®šä¹‰æŸå¤±å‡½æ•°\n",
    "from torch.nn import BCELoss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "epoch: 1 loss:0.15019 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 10 loss:0.14990 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 20 loss:0.14959 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 30 loss:0.14928 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 40 loss:0.14896 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 50 loss:0.14866 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 60 loss:0.14835 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 70 loss:0.14805 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 80 loss:0.14775 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 90 loss:0.14745 \n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "2000\n",
      "epoch: 100 loss:0.14715 \n"
     ]
    }
   ],
   "source": [
    "# æ¨¡å‹è®­ç»ƒ\n",
    "lr = 0.6\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "net = logistic\n",
    "loss = BCELoss()\n",
    "train_all_loss = []\n",
    "acc_all = []\n",
    "for epoch in range(num_epochs): # è®­ç»ƒæ¨¡å‹ä¸€å…±éœ€è¦num_epochsä¸ªè¿­ä»£å‘¨æœŸ\n",
    "    # åœ¨æ¯ä¸€ä¸ªè¿­ä»£å‘¨æœŸä¸­ï¼Œä¼šä½¿ç”¨è®­ç»ƒæ•°æ®é›†ä¸­æ‰€æœ‰æ ·æœ¬ä¸€æ¬¡\n",
    "    for X, y in data_iter(batch_size, train_data, train_labels): # xå’Œyåˆ†åˆ«æ˜¯å°æ‰¹é‡æ ·æœ¬çš„ç‰¹å¾å’Œæ ‡ç­¾\n",
    "        pred = net(X, w, b)\n",
    "        y = y.view(-1, 1)\n",
    "        train_each_loss = loss(pred, y)\n",
    "        train_each_loss.backward() # åå‘ä¼ æ’­\n",
    "        sgd([w,b], lr, batch_size) # ä½¿ç”¨å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™è¿­ä»£æ¨¡å‹å‚æ•°\n",
    "        # æ¢¯åº¦æ¸…é›¶\n",
    "        w.grad.data.zero_()\n",
    "        b.grad.data.zero_()\n",
    "    labels_pred = net(train_data, w, b)\n",
    "    train_loss = loss(labels_pred, train_labels.view(-1, 1))\n",
    "    train_all_loss.append(train_loss.item())\n",
    "    labels_pred = torch.tensor(np.where(labels_pred<0.5, 0, 1),dtype=torch.float32)\n",
    "    # acc = (labels_pred==train_labels).sum(0).item() / train_examples\n",
    "    acc = len((labels_pred==train_labels).sum(0))\n",
    "    # max_acc = max(acc,max_acc)\n",
    "    # acc_all.append(acc)\n",
    "    # if epoch==0 or (epoch+1) % 10 == 0:\n",
    "    #     print('epoch: %d loss:%.5f acc: %.3f'%(epoch+1, train_loss.item(), acc))\n",
    "    if epoch==0 or (epoch+1) % 10 == 0:\n",
    "        print('epoch: %d loss:%.5f '%(epoch+1, train_loss.item()))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
