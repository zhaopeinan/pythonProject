{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable as V\n",
    "\n",
    "input = V(t.randn(2, 3))\n",
    "model = nn.Linear(3, 4)\n",
    "output1 = model(input)  # 得到输出方式1\n",
    "output2 = nn.functional.linear(input, model.weight, model.bias)  # 得到输出方式2\n",
    "print(output1 == output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True]])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "\n",
    "input = t.randn(2, 3)\n",
    "model = nn.Linear(3, 4)\n",
    "output1 = model(input)  # 得到输出方式1\n",
    "output2 = nn.functional.linear(input,\n",
    "                               model.weight, model.bias)  # 得到输出方式2\n",
    "print(output1 == output2)\n",
    "print(output1.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self):  # 读取csv文件中的数据\n",
    "        xy = np.loadtxt('data-diabetes.csv', delimiter=',', dtype=np.float32)\n",
    "        self.len = xy.shape[0]  # 除去最后一列为数据位，存在x_data中\n",
    "        self.x_data = torch.from_numpy(xy[:, 0:-1])  # 最后一列为标签为，存y_data中\n",
    "        self.y_data = torch.from_numpy(xy[:, [-1]])\n",
    "\n",
    "    def __getitem__(self, index):  # 根据索引返回数据和对应的标签\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):  # 返回文件数据的数目\n",
    "        return self.len"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "data-diabetes.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mautograd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Variable\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# 调用自己创建的Dataset\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mMyDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(dataset\u001B[38;5;241m=\u001B[39mdataset, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m#循环来迭代来高效地获取数据\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[3], line 7\u001B[0m, in \u001B[0;36mMyDataset.__init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m): \u001B[38;5;66;03m# 读取csv文件中的数据\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m     xy \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloadtxt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata-diabetes.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfloat32\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlen \u001B[38;5;241m=\u001B[39m xy\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;66;03m# 除去最后一列为数据位，存在x_data中\u001B[39;00m\n\u001B[0;32m      9\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mx_data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(xy[:, \u001B[38;5;241m0\u001B[39m:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]) \u001B[38;5;66;03m# 最后一列为标签为，存y_data中\u001B[39;00m\n",
      "File \u001B[1;32mE:\\Program Files\\anaconda3\\envs\\pytorch_1\\lib\\site-packages\\numpy\\lib\\npyio.py:1356\u001B[0m, in \u001B[0;36mloadtxt\u001B[1;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001B[0m\n\u001B[0;32m   1353\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(delimiter, \u001B[38;5;28mbytes\u001B[39m):\n\u001B[0;32m   1354\u001B[0m     delimiter \u001B[38;5;241m=\u001B[39m delimiter\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m-> 1356\u001B[0m arr \u001B[38;5;241m=\u001B[39m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcomment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcomment\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdelimiter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1357\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconverters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconverters\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mskiplines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mskiprows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43musecols\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musecols\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1358\u001B[0m \u001B[43m            \u001B[49m\u001B[43munpack\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43munpack\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mndmin\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mndmin\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1359\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_rows\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_rows\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquote\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquotechar\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\n",
      "File \u001B[1;32mE:\\Program Files\\anaconda3\\envs\\pytorch_1\\lib\\site-packages\\numpy\\lib\\npyio.py:975\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001B[0m\n\u001B[0;32m    973\u001B[0m     fname \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(fname)\n\u001B[0;32m    974\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fname, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m--> 975\u001B[0m     fh \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_datasource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    976\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m encoding \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    977\u001B[0m         encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(fh, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlatin1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mE:\\Program Files\\anaconda3\\envs\\pytorch_1\\lib\\site-packages\\numpy\\lib\\_datasource.py:193\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(path, mode, destpath, encoding, newline)\u001B[0m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \u001B[38;5;124;03mOpen `path` with `mode` and return the file object.\u001B[39;00m\n\u001B[0;32m    158\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    189\u001B[0m \n\u001B[0;32m    190\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    192\u001B[0m ds \u001B[38;5;241m=\u001B[39m DataSource(destpath)\n\u001B[1;32m--> 193\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnewline\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\Program Files\\anaconda3\\envs\\pytorch_1\\lib\\site-packages\\numpy\\lib\\_datasource.py:533\u001B[0m, in \u001B[0;36mDataSource.open\u001B[1;34m(self, path, mode, encoding, newline)\u001B[0m\n\u001B[0;32m    530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _file_openers[ext](found, mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m    531\u001B[0m                               encoding\u001B[38;5;241m=\u001B[39mencoding, newline\u001B[38;5;241m=\u001B[39mnewline)\n\u001B[0;32m    532\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 533\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: data-diabetes.csv not found."
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# 调用自己创建的Dataset\n",
    "dataset = MyDataset()\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)\n",
    "#循环来迭代来高效地获取数据\n",
    "for i, data in enumerate(train_loader, 0):\n",
    "    # get the inputs\n",
    "    inputs, labels = data\n",
    "    # wrap them in Variable\n",
    "    inputs, labels = Variable(inputs), Variable(labels)\n",
    "    # Run your training process\n",
    "    print(\"step\", i, \"inputs\", inputs.data, \"labels\", labels.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 导入了resnet50的预训练模型\n",
    "import torchvision\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "model = torchvision.models.resnet50(pretrained=True)\n",
    "# 如果只需要网络结构，不需要用预训练模型的参数来初始化\n",
    "# model = torchvision.models.resnet50(pretrained=False)\n",
    "imagenet_data = torchvision.datasets.ImageNet('~/dataFolder/imagenet')\n",
    "# data_loader = torch.utils.data.DataLoader(imagenet_data, batch_size=4, shuffle=True, num_workers=args.nThreads)\n",
    "data_loader = torch.utils.data.DataLoader(imagenet_data, batch_size=4, shuffle=True, num_workers=cpu_count)\n",
    "torchvision.datasets.MNIST('~/dataFolder/imagenet', train=True, transform=None, target_transform=None, download=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# 解决实际问题\n",
    "# y = w * x^2 + bias\n",
    "\"\"\"\n",
    "使用深度学习解决问题的一般步骤：\n",
    "（1）定义模型与确定参数\n",
    "（2）准备数据\n",
    "（3）确定损失函数与优化器\n",
    "（4）训练并更新参数\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch\n",
    "class MyLayer(torch.nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(MyLayer, self).__init__()  # 和自定义模型一样，第一句话就是调用父类的构造函数\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = torch.nn.Parameter(torch.Tensor(in_features, out_features))  # 由于weights是可以训练的，所以使用Parameter来定义。\n",
    "        if bias:\n",
    "            self.bias = torch.nn.Parameter(torch.Tensor(in_features))  # 由于bias是可以训练的，所以使用Parameter来定义\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        def forward(self, input):\n",
    "            input_ = torch.pow(input, 2) + self.bias\n",
    "            y = torch.matmul(input_, self.weight)\n",
    "            return y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import torch\n",
    "N, D_in, D_out = 10, 5, 3 # 一共10组样本，输入特征为5，输出特征为3\n",
    "# 先定义一个模型\n",
    "class MyNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__() # 第一句话，调用父类的构造函数\n",
    "        self.mylayer1 = MyLayer(D_in,D_out)\n",
    "        def forward(self, x):\n",
    "            x = self.mylayer1(x)\n",
    "            return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyNet(\n",
      "  (mylayer1): MyLayer()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MyNet()\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 创建输入、输出数据\n",
    "x = torch.randn(N, D_in) #（10，5）\n",
    "y = torch.randn(N, D_out) #（10，3）"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum') #定义损失函数\n",
    "learning_rate = 1e-4 #定义学习率\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) #构造一个optimizer对象"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m10\u001B[39m):\n\u001B[0;32m      2\u001B[0m     \u001B[38;5;66;03m# 第一步：数据的前向传播，计算预测值p_pred\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# 第二步：计算计算预测值p_pred与真实值的误差\u001B[39;00m\n\u001B[0;32m      5\u001B[0m     loss \u001B[38;5;241m=\u001B[39m loss_fn(y_pred, y)\n",
      "File \u001B[1;32mE:\\Program Files\\anaconda3\\envs\\pytorch_1\\lib\\site-packages\\torch\\nn\\modules\\module.py:1102\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1099\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1101\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1103\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1104\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mE:\\Program Files\\anaconda3\\envs\\pytorch_1\\lib\\site-packages\\torch\\nn\\modules\\module.py:201\u001B[0m, in \u001B[0;36m_forward_unimplemented\u001B[1;34m(self, *input)\u001B[0m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_forward_unimplemented\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    191\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Defines the computation performed at every call.\u001B[39;00m\n\u001B[0;32m    192\u001B[0m \n\u001B[0;32m    193\u001B[0m \u001B[38;5;124;03m    Should be overridden by all subclasses.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    199\u001B[0m \u001B[38;5;124;03m        registered hooks while the latter silently ignores them.\u001B[39;00m\n\u001B[0;32m    200\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 201\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(10):\n",
    "    # 第一步：数据的前向传播，计算预测值p_pred\n",
    "    y_pred = model(x)\n",
    "    # 第二步：计算计算预测值p_pred与真实值的误差\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(f\"第 {t} 个epoch, 损失是 {loss.item()}\")\n",
    "    # 在反向传播之前，将模型的梯度归零\n",
    "    optimizer.zero_grad()\n",
    "    # 第三步：反向传播误差\n",
    "    loss.backward()\n",
    "    # 直接通过梯度一步到位，更新完整个网络的训练参数\n",
    "    optimizer.step()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
